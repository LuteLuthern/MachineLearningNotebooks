{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/production-deploy-to-aks-gpu/production-deploy-to-aks-gpu.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploying a web service hosted on NVIDIA Triton to Azure Kubernetes Service (AKS)\n",
        "This notebook shows the steps for deploying a service with [NVIDIA Triton Inferencing Server](https://developer.nvidia.com/nvidia-triton-inference-server): registering a model, creating an image, provisioning a cluster (one time action), and deploying a service to it. \n",
        "We then test and delete the service, image and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-core 1.13.0a0 (/home/ralf/.local/lib/python3.6/site-packages), Requirement.parse('azureml-core~=1.10.0'), {'azureml-telemetry'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-core 1.13.0a0 (/home/ralf/.local/lib/python3.6/site-packages), Requirement.parse('azureml-core~=1.10.0'), {'azureml-telemetry'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.13.0a0 (/home/ralf/.local/lib/python3.6/site-packages), Requirement.parse('azureml-core~=1.10.0')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.13.0a0 (/home/ralf/.local/lib/python3.6/site-packages), Requirement.parse('azureml-core~=1.10.0')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.13.0a0 (/home/ralf/.local/lib/python3.6/site-packages), Requirement.parse('azureml-core~=1.10.0')).\n1.13.0a0\n"
        }
      ],
      "source": [
        "import azureml.core\n",
        "print(azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get workspace\n",
        "Load existing workspace from the config file info."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "triton2\nyifyu\nwestus\n5f08d643-1910-4a38-a7c7-84a39d4f42e0\n"
        }
      ],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "#ws = Workspace.from_config()\n",
        "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"5f08d643-1910-4a38-a7c7-84a39d4f42e0\")\n",
        "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"yifyu\")\n",
        "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"triton2\")\n",
        "ws = Workspace.get(\n",
        "    subscription_id = subscription_id,\n",
        "    resource_group = resource_group,\n",
        "    name = workspace_name)\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Register the model\n",
        "Register an existing trained model, add description and tags.\n",
        "\n",
        "** Note: ** Under `model_path` there must be a sub-directory named `triton`, which has the structure of a Triton [Model Repository](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/model_repository.html#repository-layout)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Registering model densenet_onnx_orig\ndensenet_onnx_orig Image classification trained on Imagenet Dataset 4\n"
        }
      ],
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "model = Model.register(model_path=\"models\", # This points to the local directory to upload.\n",
        "                       model_name=\"densenet_onnx_orig\", # This is the name the model is registered as.\n",
        "                       tags={'area': \"Image classification\", 'type': \"classification\"},\n",
        "                       description=\"Image classification trained on Imagenet Dataset\",\n",
        "                       workspace=ws)\n",
        "\n",
        "print(model.name, model.description, model.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Provision the AKS Cluster\n",
        "This is a one time setup. You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating new gpu-cluster\nCreating...........................................................\nSucceededProvisioning operation finished, operation \"Succeeded\"\n"
        }
      ],
      "source": [
        "from azureml.core.compute import ComputeTarget, AksCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your GPU cluster\n",
        "gpu_cluster_name = \"aks-cluster-1\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
        "    print(\"Found existing gpu cluster\")\n",
        "except ComputeTargetException:\n",
        "    print(\"Creating new gpu-cluster\")\n",
        "    \n",
        "    # Specify the configuration for the new cluster\n",
        "    compute_config = AksCompute.provisioning_configuration(cluster_purpose=AksCompute.ClusterPurpose.DEV_TEST,\n",
        "                                                           agent_count=1,\n",
        "                                                           vm_size=\"Standard_F32s_v2\")\n",
        "    \n",
        "    # Create the cluster with the specified name and configuration\n",
        "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
        "\n",
        "    # Wait for the cluster to complete, show the output log\n",
        "    gpu_cluster.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy the model as a web service to AKS\n",
        "\n",
        "First create a scoring script\n",
        "\n",
        "** Note: ** Triton server listens to a fixed local port. You may choose to use the Triton Python [client library](https://docs.nvidia.com/deeplearning/triton-inference-server/master-user-guide/docs/client_library.html) to talk to it, while keeping the flexibility of pre-/post- processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting score.py\n"
        }
      ],
      "source": [
        "%%writefile score.py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import sys\n",
        "from functools import partial\n",
        "import os\n",
        "import io\n",
        "import onnxruntime\n",
        "\n",
        "from azureml.contrib.services.aml_request import AMLRequest, rawhttp\n",
        "from azureml.contrib.services.aml_response import AMLResponse\n",
        "\n",
        "sys.path.append(os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'models'))\n",
        "# sys.path.append('models')\n",
        "from utils import preprocess, postprocess\n",
        "\n",
        "_scaling = \"INCEPTION\"\n",
        "dtype = np.float32\n",
        "max_batch_size = 0\n",
        "\n",
        "def init():\n",
        "    global session, input_name, output_name, input_shape\n",
        "\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'models', 'model.onnx')\n",
        "    #model = os.path.join('models', 'model.onnx')\n",
        "    session = onnxruntime.InferenceSession(model, None)\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    input_shape = session.get_inputs()[0].shape\n",
        "    output_name = session.get_outputs()[0].name\n",
        "    print(\"input: \", input_name, \", output: \", output_name, \", input_shape: \", input_shape)\n",
        "\n",
        "\n",
        "@rawhttp\n",
        "def run(request):\n",
        "    if request.method == 'POST':\n",
        "        \n",
        "        reqBody = request.get_data(False)\n",
        "        img = Image.open(io.BytesIO(reqBody))\n",
        "        \n",
        "        result = score(img)\n",
        "\n",
        "        return AMLResponse(result, 200)\n",
        "    else:\n",
        "        return AMLResponse(\"bad request\", 500)\n",
        "\n",
        "def score(data):\n",
        "    image_data = preprocess(data, _scaling, dtype)\n",
        "    print(image_data.shape)\n",
        "    input = np.reshape(image_data, input_shape)\n",
        "    r = session.run([output_name], {input_name: input})[0]\n",
        "    print(r.shape)\n",
        "    res = r.flatten()\n",
        "    print(len(res))\n",
        "    result = postprocess(res)\n",
        "    return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    init()\n",
        "    content = Image.open(\"car.jpg\")\n",
        "    print(score(content))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now create the deployment configuration objects and deploy the model as a webservice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set the web service configuration (using default here)\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AksWebservice\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.environment import Environment\n",
        "\n",
        "env = Environment(\"test1\")\n",
        "conda_dep = CondaDependencies(\"env.yml\")\n",
        "# client_whl_url = Environment.add_private_pip_wheel(workspace=ws, file_path = os.path.join(target_folder, client_filename), exist_ok=True)\n",
        "# clientutils_whl_url = Environment.add_private_pip_wheel(workspace=ws, file_path = os.path.join(target_folder, clientutils_filename), exist_ok=True)\n",
        "# conda_dep.add_pip_package(client_whl_url)\n",
        "# conda_dep.add_pip_package(clientutils_whl_url)\n",
        "env.python.conda_dependencies = conda_dep\n",
        "\n",
        "# Specify the Azure ML Triton base image\n",
        "# env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-nvidia-tritonserver20.07-py3'\n",
        "\n",
        "# Optionally specify a worker count to leverage the capability of concurrency and server-side batching from Triton\n",
        "# env.environment_variables = {\"WORKER_COUNT\":\"128\"}\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
        "aks_config = AksWebservice.deploy_configuration(cpu_cores = 30, memory_gb = 40, auth_enabled=False, num_replicas=1, replica_max_concurrent_requests=16)\n",
        "\n",
        "# # Enable token auth and disable (key) auth on the webservice\n",
        "# aks_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 4, gpu_cores = 1, token_auth_enabled=True, auth_enabled=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Running.....\nSucceeded\nAKS service creation operation finished, operation \"Succeeded\"\nHealthy\nCPU times: user 152 ms, sys: 35.3 ms, total: 187 ms\nWall time: 38.9 s\n"
        }
      ],
      "source": [
        "%%time\n",
        "aks_service_name ='densenet-onnx-orig-1'\n",
        "\n",
        "aks_service = Model.deploy(workspace=ws,\n",
        "                           name=aks_service_name,\n",
        "                           models=[model],\n",
        "                           inference_config=inference_config,\n",
        "                           deployment_config=aks_config,\n",
        "                           deployment_target=gpu_cluster)\n",
        "\n",
        "aks_service.wait_for_deployment(show_output = True)\n",
        "print(aks_service.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test the web service\n",
        "We test the web sevice by passing the test images content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Received bad response from Model Management Service:\nResponse Code: 400\nHeaders: {'Date': 'Thu, 27 Aug 2020 09:55:23 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': 'dcaef7312af44e2390e86f25391ca9e6', 'x-ms-client-session-id': '82d4bb2e-29b2-4235-afe7-14b2fc49e973', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-request-time': '0.101', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"AuthDisabled\",\"message\":\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 5f08d643-1910-4a38-a7c7-84a39d4f42e0, ResourceGroup: yifyu, Workspace: triton2\"}],\"correlation\":{\"RequestId\":\"dcaef7312af44e2390e86f25391ca9e6\"}}'\n\n"
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Received bad response from Model Management Service:\nResponse Code: 400\nHeaders: {'Date': 'Thu, 27 Aug 2020 09:55:23 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': 'dcaef7312af44e2390e86f25391ca9e6', 'x-ms-client-session-id': '82d4bb2e-29b2-4235-afe7-14b2fc49e973', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-request-time': '0.101', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"AuthDisabled\",\"message\":\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 5f08d643-1910-4a38-a7c7-84a39d4f42e0, ResourceGroup: yifyu, Workspace: triton2\"}],\"correlation\":{\"RequestId\":\"dcaef7312af44e2390e86f25391ca9e6\"}}'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Thu, 27 Aug 2020 09:55:23 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': 'dcaef7312af44e2390e86f25391ca9e6', 'x-ms-client-session-id': '82d4bb2e-29b2-4235-afe7-14b2fc49e973', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-request-time': '0.101', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"BadRequest\\\",\\\"statusCode\\\":400,\\\"message\\\":\\\"The request is invalid.\\\",\\\"details\\\":[{\\\"code\\\":\\\"AuthDisabled\\\",\\\"message\\\":\\\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 5f08d643-1910-4a38-a7c7-84a39d4f42e0, ResourceGroup: yifyu, Workspace: triton2\\\"}],\\\"correlation\\\":{\\\"RequestId\\\":\\\"dcaef7312af44e2390e86f25391ca9e6\\\"}}'\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mget_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClientBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_requests_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_keys_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://westus.modelmanagement.azureml.net/modelmanagement/v1.0/subscriptions/5f08d643-1910-4a38-a7c7-84a39d4f42e0/resourceGroups/yifyu/providers/Microsoft.MachineLearningServices/workspaces/triton2/services/densenet-onnx-orig-1/listkeys",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mget_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    990\u001b[0m                                       \u001b[0;34m'Headers: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                                       \u001b[0;34m'Content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m                                       logger=module_logger)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Received bad response from Model Management Service:\nResponse Code: 400\nHeaders: {'Date': 'Thu, 27 Aug 2020 09:55:23 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': 'dcaef7312af44e2390e86f25391ca9e6', 'x-ms-client-session-id': '82d4bb2e-29b2-4235-afe7-14b2fc49e973', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-request-time': '0.101', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"AuthDisabled\",\"message\":\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 5f08d643-1910-4a38-a7c7-84a39d4f42e0, ResourceGroup: yifyu, Workspace: triton2\"}],\"correlation\":{\"RequestId\":\"dcaef7312af44e2390e86f25391ca9e6\"}}'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Thu, 27 Aug 2020 09:55:23 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': 'dcaef7312af44e2390e86f25391ca9e6', 'x-ms-client-session-id': '82d4bb2e-29b2-4235-afe7-14b2fc49e973', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-request-time': '0.101', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"BadRequest\\\",\\\"statusCode\\\":400,\\\"message\\\":\\\"The request is invalid.\\\",\\\"details\\\":[{\\\"code\\\":\\\"AuthDisabled\\\",\\\"message\\\":\\\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 5f08d643-1910-4a38-a7c7-84a39d4f42e0, ResourceGroup: yifyu, Workspace: triton2\\\"}],\\\"correlation\\\":{\\\"RequestId\\\":\\\"dcaef7312af44e2390e86f25391ca9e6\\\"}}'\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import requests\n",
        "\n",
        "# if (key) auth is enabled, fetch keys and include in the request\n",
        "#key1, key2 = aks_service.get_keys()\n",
        "\n",
        "#headers = {'Content-Type':'application/octet-stream', 'Authorization': 'Bearer ' + key1}\n",
        "headers = {'Content-Type':'application/octet-stream'}\n",
        "\n",
        "# # if token auth is enabled, fetch token and include in the request\n",
        "# access_token, fetch_after = aks_service.get_token()\n",
        "# headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + access_token}\n",
        "\n",
        "test_sample = open('car.jpg', 'rb').read()\n",
        "resp = requests.post(aks_service.scoring_uri, test_sample, headers=headers)\n",
        "print(key1)\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "thread 1 created\nRunning 1m test @ http://40.78.16.120:80/api/v1/service/densenet-onnx-orig-1/score\n  1 threads and 3 connections\n^C\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   166.99ms   29.66ms 399.26ms   92.26%\n    Req/Sec    18.14      4.52    30.00     77.82%\n  502 requests in 28.14s, 157.37KB read\nRequests/sec:     17.84\nTransfer/sec:      5.59KB\nthread 1 made 506 requests and got 502 responses, 4 request(s) do(es) not see response\n------------------------------\n\nRequest = 506; Responses = 502; Missing requests: 4\n------------------------------\n\nHTTP Status 2xx Count: 502\nHTTP Status 3xx Count: 0\nHTTP Status 400 Count: 0\nHTTP Status 401 Count: 0\nHTTP Status 403 Count: 0\nHTTP Status 404 Count: 0\nHTTP Status 408 Count: 0\nHTTP Status 429 Count: 0\nHTTP Status 4xx Count: 0\nHTTP Status 500 Count: 0\nHTTP Status 501 Count: 0\nHTTP Status 502 Count: 0\nHTTP Status 503 Count: 0\nHTTP Status 504 Count: 0\nHTTP Status 5xx Count: 0\nHTTP Status xxx Count: 0\n------------------------------\n\n50%,156.89ms\n90%,191.87ms\n95%,209.52ms\n99%,311.91ms\n99.9%,399.26ms\n"
        }
      ],
      "source": [
        "URI = aks_service.scoring_uri\n",
        "!./wrk -c 3 -d 1m -t 1 -s car.lua $URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clean up\n",
        "Delete the service, image, model and compute target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "aks_service.delete()\n",
        "model.delete()\n",
        "gpu_cluster.delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "densenet-onnx-orig\ndensenet-onnx-orig-1\naksservice-update\n"
        }
      ],
      "source": [
        "services = AksWebservice.list(ws)\n",
        "\n",
        "for service in services:\n",
        "    print(service.name)\n",
        "    service.delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "aks_service.delete()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "vaidyas"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python36964bit49f9d8f83b294f2eb4e5a3f7c26b67fb"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}